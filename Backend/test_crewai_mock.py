"""
CrewAI æµç¨‹æµ‹è¯• - Mock ç‰ˆæœ¬ï¼ˆä¸è°ƒç”¨çœŸå®APIï¼‰
éªŒè¯å¤šAgentåä½œæµç¨‹
"""

from crewai import Agent, Task, Crew, Process
from crewai.llm import LLM
from unittest.mock import Mock, patch
import json

print("=" * 60)
print("ğŸš€ CrewAI å¤šAgent PPT ç”Ÿæˆæµ‹è¯• (Mock)")
print("=" * 60)

# Step 1: æ¨¡æ‹Ÿ LLM å“åº”
print("\nğŸ“Œ Step 1: é…ç½® LLM (Mock)")

class MockLLM:
    """Mock LLMï¼Œè¿”å›é¢„å®šä¹‰å“åº”"""
    def __init__(self):
        self.responses = {
            "éœ€æ±‚åˆ†æ": '''{
                "topic": "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
                "target_audience": "ä¼ä¸šç®¡ç†å±‚",
                "num_slides": 5,
                "key_points": ["AIæŠ€æœ¯çªç ´", "è¡Œä¸šåº”ç”¨", "å•†ä¸šä»·å€¼", "å®æ–½ç­–ç•¥", "æœªæ¥å±•æœ›"]
            }''',
            "å¤§çº²è§„åˆ’": '''{
                "slides": [
                    {"page": 1, "type": "cover", "title": "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿"},
                    {"page": 2, "type": "content", "title": "AIæŠ€æœ¯çªç ´"},
                    {"page": 3, "type": "content", "title": "è¡Œä¸šåº”ç”¨æ¡ˆä¾‹"},
                    {"page": 4, "type": "content", "title": "å•†ä¸šä»·å€¼åˆ†æ"},
                    {"page": 5, "type": "summary", "title": "æ€»ç»“ä¸å±•æœ›"}
                ]
            }''',
            "å†…å®¹ç”Ÿæˆ": '''
ç¬¬1é¡µ - æ ‡é¢˜ï¼šäººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿
è¦ç‚¹ï¼š
- ç”Ÿæˆå¼AIå¼•é¢†æ–°ä¸€è½®æŠ€æœ¯é©å‘½
- å¤§æ¨¡å‹èƒ½åŠ›æŒç»­æå‡
- å¤šæ¨¡æ€AIæˆä¸ºæ–°è¶‹åŠ¿

ç¬¬2é¡µ - æ ‡é¢˜ï¼šAIæŠ€æœ¯çªç ´
è¦ç‚¹ï¼š
- GPT-4ç­‰æ¨¡å‹å±•ç°å¼ºå¤§èƒ½åŠ›
- ä»£ç ç”Ÿæˆå‡†ç¡®ç‡è¶…è¿‡80%
- å¤šè¯­è¨€æ”¯æŒè¦†ç›–100+è¯­ç§

ç¬¬3é¡µ - æ ‡é¢˜ï¼šè¡Œä¸šåº”ç”¨æ¡ˆä¾‹
è¦ç‚¹ï¼š
- é‡‘èï¼šæ™ºèƒ½é£æ§é™ä½æŸå¤±30%
- åŒ»ç–—ï¼šè¾…åŠ©è¯Šæ–­å‡†ç¡®ç‡95%
- åˆ¶é€ ï¼šé¢„æµ‹æ€§ç»´æŠ¤å‡å°‘åœæœº

ç¬¬4é¡µ - æ ‡é¢˜ï¼šå•†ä¸šä»·å€¼åˆ†æ
è¦ç‚¹ï¼š
- 2025å¹´å…¨çƒAIå¸‚åœºè¾¾2000äº¿ç¾å…ƒ
- ä¼ä¸šAIé‡‡ç”¨ç‡å¢é•¿300%
- ROIå¹³å‡æå‡25%

ç¬¬5é¡µ - æ ‡é¢˜ï¼šæ€»ç»“ä¸å±•æœ›
è¦ç‚¹ï¼š
- AIå·²æˆä¸ºä¼ä¸šæ ¸å¿ƒç«äº‰åŠ›
- å»ºè®®åˆ¶å®šAIæˆ˜ç•¥è§„åˆ’
- æŒç»­å…³æ³¨æŠ€æœ¯å‘å±•
'''
        }
        self.call_count = 0
    
    def call(self, messages, **kwargs):
        """æ¨¡æ‹Ÿ LLM è°ƒç”¨"""
        self.call_count += 1        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹è¿”å›å¯¹åº”å“åº”
        msg = str(messages)
        if "éœ€æ±‚" in msg or "åˆ†æ" in msg:
            return self.responses["éœ€æ±‚åˆ†æ"]
        elif "å¤§çº²" in msg or "ç»“æ„" in msg:
            return self.responses["å¤§çº²è§„åˆ’"]
        else:
            return self.responses["å†…å®¹ç”Ÿæˆ"]

mock_llm = MockLLM()
print("âœ… Mock LLM é…ç½®å®Œæˆ")

# Step 2: åˆ›å»º Agents
print("\nğŸ“Œ Step 2: åˆ›å»º Agents")

requirement_agent = Agent(
    role='éœ€æ±‚åˆ†æå¸ˆ',
    goal='åˆ†æç”¨æˆ·çš„PPTéœ€æ±‚',
    backstory='ä½ æ“…é•¿ç†è§£ç”¨æˆ·éœ€æ±‚ï¼Œæå–å…³é”®ä¿¡æ¯',
    llm=mock_llm,
    verbose=False
)
print("âœ… éœ€æ±‚åˆ†æAgent")

outline_agent = Agent(
    role='å¤§çº²è§„åˆ’å¸ˆ',
    goal='è®¾è®¡PPTç»“æ„',
    backstory='ä½ æ“…é•¿è®¾è®¡æ¸…æ™°çš„å†…å®¹ç»“æ„',
    llm=mock_llm,
    verbose=False
)
print("âœ… å¤§çº²è§„åˆ’Agent")

content_agent = Agent(
    role='å†…å®¹æ’°å†™å¸ˆ',
    goal='ç”ŸæˆPPTå†…å®¹',
    backstory='ä½ æ“…é•¿æ’°å†™ç®€æ´æœ‰åŠ›çš„PPTå†…å®¹',
    llm=mock_llm,
    verbose=False
)
print("âœ… å†…å®¹æ’°å†™Agent")

# Step 3: åˆ›å»º Tasks
print("\nğŸ“Œ Step 3: åˆ›å»º Tasks")

user_request = "å¸®æˆ‘åšä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿çš„PPTï¼Œé¢å‘ä¼ä¸šç®¡ç†å±‚ï¼Œ5é¡µå·¦å³"

task_analyze = Task(
    description=f'åˆ†æéœ€æ±‚ï¼š{user_request}',
    agent=requirement_agent,
    expected_output='JSONæ ¼å¼çš„éœ€æ±‚åˆ†æ'
)
print("âœ… Task 1: éœ€æ±‚åˆ†æ")

task_outline = Task(
    description='åŸºäºéœ€æ±‚è®¾è®¡PPTå¤§çº²',
    agent=outline_agent,
    expected_output='JSONæ ¼å¼çš„PPTå¤§çº²'
)
print("âœ… Task 2: å¤§çº²è§„åˆ’")

task_content = Task(
    description='ä¸ºæ¯é¡µPPTç”Ÿæˆå…·ä½“å†…å®¹',
    agent=content_agent,
    expected_output='æ¯é¡µPPTçš„è¯¦ç»†å†…å®¹'
)
print("âœ… Task 3: å†…å®¹ç”Ÿæˆ")

# Step 4: åˆ›å»º Crew
print("\nğŸ“Œ Step 4: ç»„å»º Crew")
crew = Crew(
    agents=[requirement_agent, outline_agent, content_agent],
    tasks=[task_analyze, task_outline, task_content],
    process=Process.sequential,
    verbose=False
)
print("âœ… Crew ç»„å»ºå®Œæˆ")

# Step 5: è¿è¡Œ
print("\n" + "=" * 60)
print("ğŸ¬ å¼€å§‹æ‰§è¡Œç”Ÿæˆæµç¨‹...")
print("=" * 60)

try:
    result = crew.kickoff()
    
    print("\n" + "=" * 60)
    print("âœ… ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    
    print("\nğŸ“Š æ‰§è¡Œç»Ÿè®¡ï¼š")
    print(f"   - LLM è°ƒç”¨æ¬¡æ•°: {mock_llm.call_count}")
    print(f"   - Agent æ•°é‡: 3")
    print(f"   - Task æ•°é‡: 3")
    
    print("\nğŸ“„ ç”Ÿæˆç»“æœé¢„è§ˆï¼š")
    print("-" * 60)
    print(result[:1000] if len(str(result)) > 1000 else result)
    print("-" * 60)
    
    print("\nğŸ” éªŒè¯ç»“æœï¼š")
    result_str = str(result)
    checks = [
        ("éœ€æ±‚åˆ†æ", "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿" in result_str or "AI" in result_str),
        ("å¤§çº²ç»“æ„", "ç¬¬" in result_str and "é¡µ" in result_str),
        ("å†…å®¹ç”Ÿæˆ", "è¦ç‚¹" in result_str or "æ ‡é¢˜" in result_str),
    ]
    for name, passed in checks:
        status = "âœ…" if passed else "âŒ"
        print(f"   {status} {name}")
    
except Exception as e:
    print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 60)
print("ğŸ‰ æµ‹è¯•æˆåŠŸï¼CrewAI å¤šAgentæµç¨‹éªŒè¯é€šè¿‡")
print("=" * 60)
print("\næµç¨‹è¯´æ˜ï¼š")
print("1ï¸âƒ£  éœ€æ±‚åˆ†æAgent ç†è§£ç”¨æˆ·æ„å›¾")
print("2ï¸âƒ£  å¤§çº²è§„åˆ’Agent è®¾è®¡PPTç»“æ„")
print("3ï¸âƒ£  å†…å®¹æ’°å†™Agent ç”Ÿæˆæ¯é¡µå†…å®¹")
print("\næ¯ä¸ªAgentå„å¸å…¶èŒï¼ŒæŒ‰é¡ºåºåä½œå®Œæˆä»»åŠ¡")
